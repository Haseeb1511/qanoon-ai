import os,sys


from fastapi import FastAPI,HTTPException,UploadFile,Form,File
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import shutil
from typing import Optional
from langchain_core.messages import HumanMessage,AIMessage
from src.graph.builder import GraphBuilder
from pathlib import Path
from langgraph.checkpoint.postgres import PostgresSaver
from src.db_connection.connection import CONNECTION_STRING
from src.utils.file_hash import get_file_hash
import uvicorn
from src.db_connection.connection import CONNECTION_STRING,supabase_client
import uuid


UPLOAD_DIR = Path("uploaded_docs")
UPLOAD_DIR.mkdir(exist_ok=True)

app = FastAPI(title="QanoonAI")

# Add CORS middleware to allow requests from any origin
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


graph_builder = GraphBuilder(checkpointer=None)



@app.post("/ask")
async def ask_question(pdf:UploadFile=File(...),question:str=Form(...)):
    """
    Upload a PDF and ask a quesiton.
    Return the anser from the chatbot
    """
    if not pdf.filename.endswith(".pdf"):
        raise HTTPException(status_code=400,detail="Only PDF file are supported for now")
    
    # save pdf file 
    pdf_path = UPLOAD_DIR/pdf.filename
    with open(pdf_path,"wb") as f:
        shutil.copyfileobj(pdf.file,f)
    

    # generate doc_id, and collection name

    doc_id = get_file_hash(str(pdf_path))
    collection_name = pdf_path.stem.lower().replace(" ","_")  #legal case.pdf --> legal_case
    thread_id = str(uuid.uuid4())
  

    with PostgresSaver.from_conn_string(CONNECTION_STRING) as checkpointer:
        checkpointer.setup()

        graph = graph_builder.__class__(checkpointer=checkpointer)()

        config = {"configurable":{"thread_id":thread_id}}

        result = graph.invoke({
                "documents_path": str(pdf_path),
                "doc_id": doc_id,
                "collection_name": collection_name,
                "messages": [HumanMessage(content=question)],
                "summary": ""
        },config=config) # type:ignore

        # save messages in supbase
        messages = [
            {"role":"human","content":question},
            {"role":"ai","content":result["answer"]}
        ]
        supabase_client.table("threads").upsert({
            "thread_id":thread_id,
            "doc_id":doc_id,
            "messages":messages
        }).execute()

        return {"answer": result["answer"], "doc_id": doc_id, "thread_id": thread_id}
    



# thread id --> It will be chat thread id which will be selected by uesr from frontend side
# doc_id --> it is generated by  get_file_hash()
# Same file → same doc_id → reuse embeddings/vectorstore
# Different file → new doc_id → new vectorstore

# for follow up wQuestion
@app.post("/follow_up")
async def follow_up(doc_id:str=Form(...),
                    question:str=Form(...),
                    thread_id:str=Form("user-123")
                    ):
    """
    Ask a follow up quesiton using the existing vectorstore
    """
    if not doc_id:
        raise HTTPException(status_code=400,detail="doc_id is required")

    #Get Previous question
    response = supabase_client.table("threads").select("messages").eq("thread_id",thread_id).execute()
    previous_messages = []
    if response.data:
        previous_messages = response.data[0]["messages"] 

    # append new humman message
    previous_messages.append({"role":"human","content":question})

    # Lookup collection_name
    response_doc = supabase_client.table("documents").select("file_name").eq("doc_id", doc_id).limit(1).execute()
    if not response_doc.data:
        raise HTTPException(status_code=404, detail="Document not found")
    file_name = response_doc.data[0]["file_name"]
    collection_name = file_name.rsplit(".", 1)[0].lower().replace(" ", "_")

   # call graph
    with PostgresSaver.from_conn_string(CONNECTION_STRING) as checkpointer:
        checkpointer.setup()
        graph = graph_builder.__class__(checkpointer=checkpointer)()
        config = {"configurable": {"thread_id": thread_id}}

        # Pass follow-up message
        result = graph.invoke({
            "doc_id": doc_id,
            "collection_name": collection_name,
            "messages": [HumanMessage(content=m["content"]) for m in previous_messages]
        }, config=config)

        # previous message contain all previos message and current messages
    # Append AI response
    previous_messages.append({"role": "ai", "content": result["answer"]})

    # Update Supabase
    supabase_client.table("threads").update({"messages": previous_messages}).eq("thread_id", thread_id).execute()
    return {"result":result["answer"]}






@app.get("/get_threads/{thread_id}")
async def get_threads(thread_id: str):
    """
    Get a specific thread's data including messages and doc_id
    """
    try:
        response = supabase_client.table("threads").select("*").eq("thread_id", thread_id).single().execute()
        
        if response.data:
            return {
                "thread_id": response.data["thread_id"],
                "doc_id": response.data["doc_id"],
                "messages": response.data["messages"]
            }
        else:
            raise HTTPException(status_code=404, detail="Thread not found")
    except Exception as e:
        raise HTTPException(status_code=404, detail=f"Thread not found: {str(e)}")



@app.get("/all_threads")
async def get_all_threads():
    """
    Get all threads with their IDs and the first message (preview).
    """
    try:
        response = supabase_client.table("threads").select("thread_id, doc_id, messages").execute()
        threads = []
        if response.data:
            for thread in response.data:
                # Extract file name from doc_id if possible, or just use doc_id
                # For now, we'll try to get the first message as a title/preview
                messages = thread.get("messages", [])
                preview = "New Chat"
                if messages and len(messages) > 0:
                    preview = messages[0].get("content", "New Chat")[:50] + "..."
                
                threads.append({
                    "thread_id": thread["thread_id"],
                    "doc_id": thread["doc_id"],
                    "preview": preview
                })
        return threads
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))




@app.get("/")
async def root():
    return {"message":"QanoonAI API is running"}



if __name__=="__main__":
    uvicorn.run(app, host="127.0.0.1", port=8000)







# uv run uvicorn backend.app:app --reload

#http://127.0.0.1:8000/docs
# "vectorstore_uploaded": False

# curl -X POST "http://127.0.0.1:8000/ask" \
#   -F "pdf=@PAKISTAN PENAL CODE.pdf" \
#   -F "question=What is punishment for false claim?"

# curl -X POST "http://127.0.0.1:8000/follow_up" \
#   -F "doc_id=PASTE_DOC_ID_HERE" \
#   -F "question=Explain in simple terms"
